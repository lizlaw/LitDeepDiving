---
title: "Semi-automated rapid evidence mapping"
subtitle: "Slides & scripts: https://github.com/lizlaw/LitDeepDiving"
author: "Liz Law, Matt Grainger"
date: "11/9/2020"
output: 
    ioslides_presentation:
        widescreen: true
        css: styles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache=TRUE)
```

## Patience please :)
Liz is learning how to do these slides with R-markdown in a safe and friendly environment.
Sorry for the lack of pretty details etc.

![](https://media.giphy.com/media/UxREcFThpSEqk/giphy.gif)

## Motivating problem(s) 
- Complex search terms (AND, OR, NEAR…TOPICS, TITLES, TYPES… SOURCES, YEARS…)
- Unknown search terms (familiar with only part of the literature)
- Getting too much literature (and lots of junk)
- Getting not enough literature (missing many key papers)


--- 

![](https://media.giphy.com/media/7E8lI6TkLrvvAcPXso/giphy.gif)

Particularly issues with broad/complex/interdisciplinary issues (like everything conservation) this can be quickly overwhelming...

## Example of the problem
Aim: summarise evidence for impacts of managed bees on native bees

Broad, complex, interdisciplinary topic: 

- managed bees can be Apis, Bombus, ...
- native bees can also be many 
- common names ("honeybee", "pollinators", ...) 
- many direct (nesting, foraging) and indirect (plant, pests, pesticides) interactions
- overlap of literatures: entomology, plant ecology, ecosystem services,...

## Example of the problem - search terms
| Category| Term list |
|:--------|:----------|
|Managed|(African* NEAR bee) OR Apis OR Bombus OR "bumble bee" OR bumblebee* OR "honey bee" OR honeybee OR ((introduc* OR inva* OR non-native OR nonnative OR commercial OR exotic OR feral OR managed) NEAR (bee OR pollin*))| 
|Native|(((cavity OR ground) NEAR nesting) OR (native OR solitary OR wild)) NEAR (bee OR pollin*)|
|Interaction|pollinat* OR network* OR “niche overlap” OR “partitioning” OR interact* OR competit* OR facilitat* OR mutualis* OR “resource limitation” OR hybridization OR introgression OR dependence OR assemblag* OR overlap OR spillover OR impact*|

## Example of the problem - search results
| Search                               | Number of results |
|:-------------------------------------|:------------------|
|TOPIC(M AND N AND I), ALL             | 2,406 |
|TOPIC(M AND N), TITLE(I), ALL         | 1,127 |
|TITLE(M AND N AND I), ALL             |   194 |
|TOPIC(M AND N AND I), ALL, _near> and_| 3,746 |
|TOPIC(M AND N AND I), DocType = Review|   167 |
|TOPIC(M AND N AND I AND review terms) | 258 (95)|

: Searched Web of Science on 11/16/2020

## Two solutions (not mutually exclusive) {.columns-2}
Improve/narrow search terms further  
```{r, out.width=300}
   knitr::include_graphics('png/OneEyeDeer.png')
```

<p class="forceBreak"></p>

Characterise the literature first, then select groups to include  
```{r, out.width=300}
   knitr::include_graphics('png/NoEyeDeer.png')
```

## Improving/narrowing search terms: {.smaller}

More specificity 

- include NEAR, NOT, SAME
- restrict research areas / journals
- see e.g.: 
    - [WoS Advanced search](https://images.webofknowledge.com/WOKRS535R100/help/WOS/hp_advanced_search.html)
    - [WoS Boolean terms](https://images.webofknowledge.com/images/help/WOS/hs_search_operators.html)

Arbitrary cut-offs

- years, language, document types
- select top-n by times cited, relevance (Title, Abstract, Keywords, Keywords Plus)

Emerging approaches

- semi-automated extraction of search terms
- word groups (N-grams, or word co-occurences in ordered sets)

## General advice for searching

MATT to add 

[KeyWords Plus](https://support.clarivate.com/ScientificandAcademicResearch/s/article/KeyWords-Plus-generation-creation-and-changes?language=en_US): important words extracted from the _title of references cited_ (WoS only). Included in TOPIC search (along with title and author-supplied keywords). 


## Improving search terms: litsearchr  {.columns-2}
```{r, out.width=450}
   knitr::include_graphics('https://elizagrames.github.io/litsearchr/styles/litsearchr-hex.png')
```

- partially automates keyword selection and writing Boolean search strings
- uses the Rapid Automatic Keyword Extraction algorithm to identify potential keywords from a scoping search 
- selects important keywords based on their importance in a keyword co-occurrence network
- after keywords are grouped into concept groups, litsearchr writes Boolean searches

## litsearchr example 1.1: Load example literature

Using the Red-cockaded woodpecker example in {package::litsearchr}

- We use a "scoping search" to get some literature and deduplicate (n = 156)

```{r litsearchr example, echo=FALSE, message=FALSE, warning=FALSE}

library(litsearchr)
library(synthesisr)
library(tidyverse)

file_names <- c(
  system.file("extdata", "scopus.ris", package = "synthesisr"),
  system.file("extdata", "zoorec.txt", package = "synthesisr"))
data <- synthesisr::read_refs(file_names)

cleaned_data <- synthesisr::deduplicate(data,
                                        match_by = "title",
                                        method = "string_osa",
                                        rm_punctuation = TRUE,
                                        to_lower = TRUE)
```


```{r echo=FALSE}

knitr::kable(cleaned_data %>% 
  select(year, title) %>% 
  head(3))
  
```

## litsearchr example 1.2: Find co-occuring keywords

- Then using the "rake" algorithm we find co-occurring keywords from the abstracts

```{r}
rake_keywords <- litsearchr::extract_terms(cleaned_data$abstract,
                                           method = "fakerake",
                                           min_freq = 5,
                                           stopwords ="English")

knitr::kable(sample_n(as_tibble(rake_keywords)
         , 5))

```

```{r echo=FALSE}
naive_dfm <- litsearchr::create_dfm(
  elements = cleaned_data$abstract,
  features = rake_keywords)
naive_graph <- litsearchr::create_network(
  search_dfm = as.matrix(naive_dfm),
  min_studies = 1,
  min_occ = 1)
spline_cutoff <- litsearchr::find_cutoff(naive_graph,
                                         method = "cumulative",
                                         percent = 0.3,
                                         knot_num = 3)
reduced_graph <- litsearchr::reduce_graph(naive_graph,
                                          cutoff_strength = spline_cutoff)
search_terms <- litsearchr::get_keywords(reduced_graph)
#Finally, we can group terms together and write a Boolean search:
 search_groups <- split(search_terms,
                       factor(
                         2 - as.numeric(grepl("forest|log", search_terms)),
                         levels = seq_len(2),
                         labels = c("forest", "not forest")))
woodpecker_search <- litsearchr::write_search(search_groups,
                                              languages = "English",
                                              stemming = TRUE,
                                              closure = "left",
                                              exactphrase = TRUE,
                                              writesearch = FALSE,
                                              verbose = TRUE)
```

## litsearchr example 1.3: Reduce keywords

- Then we can reduce these keywords down to a smaller set

```{r keyword graph}

plot(reduced_graph)
```

## litsearchr example 1.4: Output search string

- Then we can output a search string. 

Search terms are outputted automatically: `r paste0(woodpecker_search) `

WoS search: TOPIC: (("burn* forest* "  OR "salvag* logging")  AND ("back* woodpeck* "  OR "picoid* arcticus*"))
= 52 articles (input in 156)

## litsearchr example 2.1: Bee literature, suggested papers

Using our Bee literature

- our team suggested 16 papers that would be suitable
- Same process as before (except min_freq = 2)

```{r litsearchr example 2, echo=FALSE, message=FALSE, warning=FALSE}

library(litsearchr)
library(synthesisr)
library(tidyverse)

file_names <- "data/suggested.bib"
data <- synthesisr::read_refs(file_names)

cleaned_data <- synthesisr::deduplicate(data,
                                        match_by = "title",
                                        method = "string_osa",
                                        rm_punctuation = TRUE,
                                        to_lower = TRUE)

rake_keywords <- litsearchr::extract_terms(cleaned_data$abstract,
                                           method = "fakerake",
                                           min_freq = 2,
                                           stopwords ="English")

naive_dfm <- litsearchr::create_dfm(
  elements = cleaned_data$abstract,
  features = rake_keywords)
naive_graph <- litsearchr::create_network(
  search_dfm = as.matrix(naive_dfm),
  min_studies = 1,
  min_occ = 1)
spline_cutoff <- litsearchr::find_cutoff(naive_graph,
                                         method = "cumulative",
                                         percent = 0.3,
                                         knot_num = 3)
reduced_graph <- litsearchr::reduce_graph(naive_graph,
                                          cutoff_strength = spline_cutoff)
search_terms <- litsearchr::get_keywords(reduced_graph)
#Finally, we can group terms together and write a Boolean search:
bee_search <- litsearchr::write_search(search_terms,
                                              languages = "English",
                                              stemming = TRUE,
                                              closure = "left",
                                              exactphrase = TRUE,
                                              writesearch = FALSE,
                                              verbose = TRUE)
```

Search terms: `r paste0(bee_search) `

TOPIC: (("climat* chang* ")  AND ("ecosystem* servic* ")  AND ("pollin* popul* ")  AND ("pollin* servic*"))  
= 6 results, all relevant, but possibly a little restrictive!

## summary on litsearcher

Benefits: 

- really great for narrowing down useful co-occurence terms

Caveats:

- needs good sample literature


## Approach #2: Grouping the literature, then narrow down

Concept is to utilize the citation records to group the literature

'Clustering' can utilize data from keywords, cited references, journals, and/or terms extracted from titles and abstracts

Characterise the clusters by keywords, "topic models", "reading lists"

Options in Scimeetr, revtools, bibliometrix


## scimeetr {.smaller .columns-2}

Designed to "help explore the literature" by

- characterising literature communities by keywords (title, abstract, keywords, keywords+, and cited references)
- return tags, top keywords, authors, cited literature
- generate reading lists by ranking, OR bibiography network characteristics

Clustering based on

- `igraph::cluster_louvain()` or `igraph::cluster_fast_greedy()` (self-stopping)
- using cited references, keywords, title, abstract (some cleaning using `tm`)

Caveats: 

- only on github, 'beta' version, ? on further development
- may need some further 'cleaning' and customising
- for example:
     - Year is missing for many interesting early access
     - may need 'stemming' of keywords, for some purposes
     - may need to identify 'synonyms' and possibly compount terms in data cleaning.

## scimeetr example - load data
Load as tab delimited files
```{r echo=TRUE, warnings=FALSE, message=FALSE}

# install.packages
# if (!require("devtools")) install.packages("devtools")
# devtools::install_github("MaximeRivest/scimeetr")

library(tidyverse) # programming
library(scimeetr) # bibiometric analysis and determination of sub-communities

dd <- "./data/raw_WoS_20201105/as_txt/"
scimeetr_list <- import_wos_files(dd)
```

## scimeetr example - the scimeetr object
The scimeetr object includes the biblio-data, and some summaries (tags, keywords, top authors)
Summary can give a little more overview
```{r echo=TRUE}
names(scimeetr_list$com1)
scimeetr_list
```

---

Summary can give a little more overview
```{r echo=TRUE}
summary(scimeetr_list)
```

## scimeetr example - define sub-communities
Here coupling bibliography, keywords (recommends also including title, and journal information = 'bickecticjoc')
This can be done heirarchically/iteratively (`scimap(scisub, coupling_by = 'bickec')`)
Default is community_algorithm = 'louvain', min_com_size = 30
```{r echo=TRUE}
scisub <- scimap(scimeetr_list, coupling_by = 'bickec')
plot(summary(scisub, com_size = 30))

```

---

```{r echo=TRUE}
summary(scisub)
```

## scimeetr example - reading lists {.smaller}
We can also characterise a corpus by extracting the top ranked papers (a 'reading list'). Several sets of options are available:

- core_papers: rank by most cited 
- core_yr: most cited per year (from yrs -3 to -10)
- core_residual: rank by largest divergence from expected (based on fitted trend by age)

- by_expert_LC: returns m papers by k highest ranked (local harmonised H-index) authors
- by_expert_TC: returns m papers by k highest ranked (total harmonised H-index) authors
- group_of_experts_TC: returns m papers by k highest ranked (local harmonised H-index) author groups
- group_of_experts_LC: returns m papers by k highest ranked (total harmonised H-index) author groups

- cite_most_others: ranked by citations (review and well researched)
- betweeness: interdisciplinary
- closeness: large and wide list of citations
- connectness: tend to have cited what most other studies cited.


---

```{r echo=TRUE}
# !! most cited cited references, not most cited articles 
dive_to(scisub, aim_at = "com1_1") %>% scilist(reading_list = "core_residual") 

dive_to(scisub, aim_at = "com1_1") %>% scilist(reading_list = "cite_most_others")
```

## scimeetr example - futher funcitons
See the github repository for [scimeetr](https://github.com/MaximeRivest/scimeetr) of [this talk](https://github.com/lizlaw/LitDeepDiving) for more scimeetr functionality examples, customized functions and cautions

## bibliometrix

Similarly to scimeetr

- provides an easy way to characterise the data
- e.g. plots by year

Differently to scimeetr

- More network plot options (plot co-author, country networks)
- Fewer integrated grouping options
- R-cran, more stable (?)

Clustering based on:

- keywords, title, OR abstract (optional 'stemming')
- Multiple Correspondence Analysis (default), or CA, MDS
- then k-means clustering on this (k = "auto" or user-supplied)

Caveats

- similarly to scimeetr, data may need pre-cleaning
- annoying change of column labels from wos import

## bibliometrix example

MATT to Add??

## summary on litsearchr, scimeetr, bibliometrix

- litsearchr useful, but should be part of a process including
- scimeetr (Liz' preference) or bibliometrix

BUT

- best practice would be iterative, documented (eg. in R)
- AND involve further cleaning, processing of data & terms

## Going further

Facilitated title and abstract screening using revtools

- allocates randomly to participants
- title, blinded to other details (authors etc)
- in/out/unsure

And/or...

## Diving deeper

doi2text

- automates finding of full text 
- identifies sections

text mining of (primary) literature 

e.g.

- searching for specific terms within the methods/results text 
  - species / species types 
  - landscapes / locations
  - sampling methods (pan, malaise, netting, etc)
- searching for data in figures and tables through legends
  
caveats(?) 

  - needs to be fed in 'lists' 
  - but this useful for standardisation of the literature
  - we can potentially automate creation of these lists via text mining

## summary
Literature searches are extremely subjective

 - what words/terms to include
 - how to combine
 - which fields to search
 - how to narrow down to a manageable set
 
Automated search tools apply algorithms to make at least part of the process transparent and repeatable.

- despite requiring many more subjective decisions
- attention to :
   - stopwords, stemming, N-grams
   - quality data in

Algorithms: for generating 'topics' and clustering them (e.g. [this link uses both](https://doi.org/10.2196/jmir.6045) )

![](https://media.giphy.com/media/VcizxCUIgaKpa/giphy.gif)
![](https://media.giphy.com/media/atcqQ5PuX41J6/giphy.gif)
