---
title: "Semi-automated rapid evidence mapping"
author: "Liz Law, Matt Grainger"
date: "11/9/2020"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Semi-automated rapid evidence mapping
Example: mapping the evidence for impacts of managed bees on native bees

## Patience please :)
Liz is learning how to do these slides with R-markdown in a safe and friendly environment.
Sorry for the lack of pretty details etc.

![](https://media.giphy.com/media/UxREcFThpSEqk/giphy.gif)



## Searching the literature

Motivating problem(s)

- Complex search terms (AND, OR, NEAR…TOPICS, TITLES, TYPES… SOURCES, YEARS…)
- Unknown search terms (familiar with only part of the literature)
- Getting too much literature (and lots of junk)
- Getting not enough literature (missing many key papers)

Particularly issues with broad/complex issues (like everything conservation)

## General advice for searching

MATT to add 

## Example
Aim: summarise evidence for impacts of managed bees on native bees

Many aspects: Foraging, Nesting, Disease/pests/pesticides/introgression, Plant-mediated
Many covariates: Types of bees, habitats, 'treatments' 

## Two solutions (not mutually exclusive)

litsearchr :: semi automated search terms

scimeetr / bibiometrix :: group/characterise the literature

## litsearchr 

- partially automates keyword selection and writing Boolean search strings
- uses the Rapid Automatic Keyword Extraction algorithm to identify potential keywords from a scoping search 
- selects important keywords based on their importance in a keyword co-occurrence network
- after keywords are grouped into concept groups, litsearchr writes Boolean searches


## litsearchr example 1

Using the Red-cockaded woodpecker example in {package::litsearchr}

- We use a "scoping search" to get some literature and deduplicate

```{r litsearchr example, echo=FALSE, message=FALSE, warning=FALSE}

library(litsearchr)
library(synthesisr)
library(tidyverse)

file_names <- c(
  system.file("extdata", "scopus.ris", package = "synthesisr"),
  system.file("extdata", "zoorec.txt", package = "synthesisr"))
data <- synthesisr::read_refs(file_names)

cleaned_data <- synthesisr::deduplicate(data,
                                        match_by = "title",
                                        method = "string_osa",
                                        rm_punctuation = TRUE,
                                        to_lower = TRUE)
```


```{r echo=FALSE}

knitr::kable(cleaned_data %>% 
  select(year, title) %>% 
  head(3))
  
```

## litsearchr example 2

- Then using the "rake" algorithm we find co-occurring keywords from the abstracts

```{r}
rake_keywords <- litsearchr::extract_terms(cleaned_data$abstract,
                                           method = "fakerake",
                                           min_freq = 5,
                                           stopwords ="English")

knitr::kable(sample_n(as_tibble(rake_keywords)
         , 5))

```

```{r echo=FALSE}
naive_dfm <- litsearchr::create_dfm(
  elements = cleaned_data$abstract,
  features = rake_keywords)
naive_graph <- litsearchr::create_network(
  search_dfm = as.matrix(naive_dfm),
  min_studies = 1,
  min_occ = 1)
spline_cutoff <- litsearchr::find_cutoff(naive_graph,
                                         method = "cumulative",
                                         percent = 0.3,
                                         knot_num = 3)
reduced_graph <- litsearchr::reduce_graph(naive_graph,
                                          cutoff_strength = spline_cutoff)
search_terms <- litsearchr::get_keywords(reduced_graph)
#Finally, we can group terms together and write a Boolean search:
 search_groups <- split(search_terms,
                       factor(
                         2 - as.numeric(grepl("forest|log", search_terms)),
                         levels = seq_len(2),
                         labels = c("forest", "not forest")))
woodpecker_search <- litsearchr::write_search(search_groups,
                                              languages = "English",
                                              stemming = TRUE,
                                              closure = "left",
                                              exactphrase = TRUE,
                                              writesearch = FALSE,
                                              verbose = TRUE)
```

## litsearchr example 3

- Then we can reduce these keywords down to a smaller set

```{r keyword graph}

plot(reduced_graph)
```

## litsearchr example 4

- Then we can output a search string. 

Search terms are outputted automatically: `r paste0(woodpecker_search) `

## scimeetr 

Designed to "help explore the literature" by

- characterising literature communities by keywords (title, abstract, keywords, keywords+, and cited references)
- return tags, top keywords, authors, cited literature
- generate reading lists by ranking, OR bibiography network characteristics

Clustering based on:

- igraph::cluster_louvain() or igraph::cluster_fast_greedy() (self-stopping)
- using cited references, keywords, title, abstract (some cleaning using tm)

Caveats: 

- only on github, 'beta' version, ? on further development
- may need some further 'cleaning' and customising
- for example:
     - Year is missing for many interesting early access
     - may need 'stemming' of keywords, for some purposes

## scimeetr example

* add example here

## bibliometrix

Similarly to scimeetr

- provides an easy way to characterise the data
- e.g. plots by year

Differently to scimeetr

- More network plot options (plot co-author, country networks)
- Fewer integrated grouping options
- R-cran, more stable (?)

Clustering based on:

- keywords, title, OR abstract (optional 'stemming')
- Multiple Correspondence Analysis (default), or CA, MDS
- then k-means clustering on this (k = "auto" or user-supplied)

Caveats

- similarly to scimeetr, data may need pre-cleaning
- annoying change of column labels from wos import

## bibliometrix example

MATT to Add??

## Diving deeper

doi2text

- automates finding of full text 
- identifies sections

text mining of (primary) literature

- e.g.
- searching for specific terms within the methods/results text 
  - species / species types 
  - landscapes / locations
  - sampling methods (pan, malaise, netting, etc)
- searching for data in figures and tables through legends
  
- caveat(?) 
  - needs to be fed in 'lists' 
  - but this useful for standardisation of the literature
  - we can potentially automate creation of these lists via text mining


